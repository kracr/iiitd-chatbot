{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import json\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def read_text(filename):\n",
    "    raw_text = ''\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            raw_text += line\n",
    "    return raw_text\n",
    "\n",
    "def write_text(text, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for line in text:\n",
    "            file.write(line)\n",
    "            \n",
    "def read_json(filename):\n",
    "    with open(filename) as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract subjects, relations and objects using regex\n",
    "\n",
    "## Regex      \n",
    "```\n",
    "(?P<sentence>\n",
    "    (?:\n",
    "        (?P<modifiers0>\n",
    "            ((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*)?)*\n",
    "        ),\n",
    "    )?(?P<subject>\n",
    "        N+(?:CN+)*\n",
    "    )[,]?(?P<modifiers1>\n",
    "        ((?:A+(?:CA+)*)(?:N+(?:CN+)*))*\n",
    "    )(?P<relation>\n",
    "        [VA]+(?:C[VA]+)*\n",
    "    )(?P<object>\n",
    "        N+(?:CN+)*\n",
    "    )?(?P<modifiers2>\n",
    "        ((?:A+(?:CA+)*)(?:N+(?:CN+)*))*\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '(?:(?:((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*)?)*),)?(?:(?:N+(?:[C,]+N+)*)(?:((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*))*)(?:[VA]*V+[VA]*(?:[C,]+[VA]*V+[VA]*)*)(?:N+(?:[C,]+N+)*)?(?:((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*))*))'\n",
    "sentence_with_groups = '(?P<sentence>(?:(?P<modifiers0>((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*)?)*),)?(?P<subject>N+(?:[C,]+N+)*)(?P<modifiers1>((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*))*)(?P<relation>[VA]*V+[VA]*(?:[C,]+[VA]*V+[VA]*)*)(?P<object>N+(?:[C,]+N+)*)?(?P<modifiers2>((?:A+(?:[C,]+A+)*)(?:N+(?:[C,]+N+)*))*))'\n",
    "re_sentences = re.compile('(' + sentence + ')([C,]+' + sentence + ')*' )\n",
    "re_sentence = re.compile(sentence_with_groups)\n",
    "re_modifiers = re.compile('(?P<modifier>(?P<m_rel>A+(?:[C,]+A+)*)(?P<m_obj>N+(?:[C,]+N+)*))(?P<remaining>(?:A+(?:[C,]+A+)*N+(?:[C,]+N+)*)*)')\n",
    "re_compound = re.compile('(?P<first>[NVA]+)(?P<remaining>(?:[C,]+[NVA]+)*)')\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    dont_split = set(['mr', 'ms', 'mrs', 'etc', 'dr', 'no'])\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for c in range(len(text)):\n",
    "        if text[c] == '.' and c + 2 < len(text) and text[c + 2].lower() != text[c + 2] and ''.join(sentence).split()[-1].lower() not in dont_split:\n",
    "                sentences.append(''.join(sentence))\n",
    "                sentence = []\n",
    "        else:\n",
    "            sentence.append(text[c])\n",
    "    sentences.append(''.join(sentence))\n",
    "    return sentences\n",
    "\n",
    "def get_sentence_structure(sentence):\n",
    "    pos_ind = {\n",
    "        'NOUN': 'N', \n",
    "        'PROPN': 'N', \n",
    "        'ADJ': 'N', \n",
    "        'DET': 'N', \n",
    "        'NUM': 'N', \n",
    "        'PART': 'N', \n",
    "        'PRON': 'N',\n",
    "        'AUX': 'V', \n",
    "        'VERB': 'V', \n",
    "        'ADV': 'V',\n",
    "        'ADP': 'A',\n",
    "        'CCONJ': 'C', \n",
    "        'SCONJ': 'C',\n",
    "        'COMMA': ',',\n",
    "        'PUNCT': '',\n",
    "        'SYM': '',\n",
    "        'SPACE': '',\n",
    "        'X': '',\n",
    "        'INTJ': ''\n",
    "    }\n",
    "    sent = nlp(sentence)\n",
    "    \n",
    "    pos_tags = []\n",
    "    tokens = []\n",
    "    for i in range(len(sent)):\n",
    "        if ',' in sent[i].text and sent[i].pos_ == 'PUNCT':\n",
    "            pos_tags.append(pos_ind['COMMA'])\n",
    "            tokens.append(sent[i].text)\n",
    "\n",
    "            continue\n",
    "        if sent[i].pos_ == 'VERB' and sent[i].text[-3:] == 'ing' and i > 0 and sent[i - 1].pos_ != 'AUX':\n",
    "            pos_tags.append(pos_ind['ADP'])\n",
    "            tokens.append(sent[i].text)\n",
    "            continue\n",
    "        if sent[i].pos_ == 'VERB' and sent[i].text[-2:] == 'ed' and (i == 0 or sent[i - 1].pos_ != 'AUX') and i + 1 < len(sent) and sent[i + 1].pos_ == 'ADP':\n",
    "            pos_tags.append(pos_ind['ADP'])\n",
    "            tokens.append(sent[i].text)\n",
    "            continue\n",
    "        if sent[i].text.lower() == 'because' and i < len(sent) and sent[i + 1].text.lower() == 'of':\n",
    "            pos_tags.append('A')\n",
    "            tokens.append(sent[i].text)\n",
    "            continue\n",
    "#         print(sent[i].text, sent[i].pos_)\n",
    "        if pos_ind[sent[i].pos_]:\n",
    "            pos_tags.append(pos_ind[sent[i].pos_])\n",
    "            tokens.append(sent[i].text)\n",
    "    \n",
    "    tokens = [tokens[i] for i in range(len(tokens)) if pos_tags[i] not in ['C', ',']]\n",
    "    sentence_structure = []\n",
    "    i = 0\n",
    "    while i < len(pos_tags):\n",
    "        if not pos_tags[i] in [pos_ind['COMMA'], pos_ind['CCONJ'], pos_ind['SCONJ']] or i + 1 < len(pos_tags) and not pos_tags[i + 1] in [pos_ind['COMMA'], pos_ind['CCONJ'], pos_ind['SCONJ']]:\n",
    "            sentence_structure.append(pos_tags[i])\n",
    "        i += 1\n",
    "    sentence_structure = ''.join(sentence_structure)\n",
    "    return sentence_structure, tokens\n",
    "\n",
    "    \n",
    "def extract(sentence):\n",
    "    if 'such as' in sentence.lower():\n",
    "        return []\n",
    "    \n",
    "    sentence_structure, tokens = get_sentence_structure(sentence)\n",
    "    extractions= find_match(sentence_structure)\n",
    "\n",
    "    ind = 0\n",
    "    for sentence in extractions:\n",
    "        for modifier in sentence['modifiers0']:\n",
    "            for i in range(len(modifier['m_rel'])):\n",
    "                rel = modifier['m_rel'][i]\n",
    "                modifier['m_rel'][i] = ' '.join(tokens[ind: ind + len(rel)])\n",
    "                ind += len(rel)\n",
    "            for i in range(len(modifier['m_obj'])):\n",
    "                obj = modifier['m_obj'][i]\n",
    "                modifier['m_obj'][i] = ' '.join(tokens[ind: ind + len(obj)])\n",
    "                ind += len(obj)\n",
    "\n",
    "\n",
    "        for i in range(len(sentence['subject'])):\n",
    "            sub = sentence['subject'][i]\n",
    "            sentence['subject'][i] = ' '.join(tokens[ind: ind + len(sub)])\n",
    "            ind += len(sub)\n",
    "\n",
    "        for modifier in sentence['modifiers1']:\n",
    "            for i in range(len(modifier['m_rel'])):\n",
    "                rel = modifier['m_rel'][i]\n",
    "                modifier['m_rel'][i] = ' '.join(tokens[ind: ind + len(rel)])\n",
    "                ind += len(rel)\n",
    "            for i in range(len(modifier['m_obj'])):\n",
    "                obj = modifier['m_obj'][i]\n",
    "                modifier['m_obj'][i] = ' '.join(tokens[ind: ind + len(obj)])\n",
    "                ind += len(obj)\n",
    "\n",
    "        for i in range(len(sentence['relation'])):\n",
    "            rel = sentence['relation'][i]\n",
    "            sentence['relation'][i] = ' '.join(tokens[ind: ind + len(rel)])\n",
    "            ind += len(rel)\n",
    "\n",
    "        for i in range(len(sentence['object'])):\n",
    "            obj = sentence['object'][i]\n",
    "            sentence['object'][i] = ' '.join(tokens[ind: ind + len(obj)])\n",
    "            ind += len(obj)\n",
    "\n",
    "        for modifier in sentence['modifiers2']:\n",
    "            for i in range(len(modifier['m_rel'])):\n",
    "                rel = modifier['m_rel'][i]\n",
    "                modifier['m_rel'][i] = ' '.join(tokens[ind: ind + len(rel)])\n",
    "                ind += len(rel)\n",
    "            for i in range(len(modifier['m_obj'])):\n",
    "                obj = modifier['m_obj'][i]\n",
    "                modifier['m_obj'][i] = ' '.join(tokens[ind: ind + len(obj)])\n",
    "                ind += len(obj)\n",
    "\n",
    "    return extractions\n",
    "\n",
    "def find_match(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    match = re_sentences.fullmatch(text)\n",
    "    if not match:\n",
    "        return []\n",
    "    sentences = find_match(match.group(0)[match.end(1) + 1:])\n",
    "    return [break_sentence(match.group(1))] + sentences\n",
    "\n",
    "def break_sentence(sentence):\n",
    "    match = re_sentence.fullmatch(sentence)\n",
    "    extractions = match.groupdict()\n",
    "    extractions['subject'] = break_compound(extractions['subject'])\n",
    "    extractions['relation'] = break_compound(extractions['relation'])\n",
    "    extractions['object'] = break_compound(extractions['object'])\n",
    "    extractions['modifiers0'] = break_modifiers(extractions['modifiers0'])\n",
    "    extractions['modifiers1'] = break_modifiers(extractions['modifiers1'])\n",
    "    extractions['modifiers2'] = break_modifiers(extractions['modifiers2'])\n",
    "\n",
    "    return extractions\n",
    "\n",
    "def break_modifiers(modifiers):\n",
    "    if not modifiers:\n",
    "        return []\n",
    "    match = re_modifiers.fullmatch(modifiers)\n",
    "    if not match:\n",
    "        return []\n",
    "    modifier = {\n",
    "        'm_rel': break_compound(match.group('m_rel')),\n",
    "        'm_obj':break_compound( match.group('m_obj'))\n",
    "    }\n",
    "    modifiers = break_modifiers(match.group('remaining'))\n",
    "    return [modifier] + modifiers\n",
    "\n",
    "def break_compound(compound):\n",
    "    if not compound:\n",
    "        return []\n",
    "    match = re_compound.fullmatch(compound)\n",
    "    if not match:\n",
    "        return []\n",
    "    parts = break_compound(match.group('remaining')[1:])\n",
    "    return [match.group('first')] + parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNNVN ['dog', \"'s\", 'food', 'is', 'good']\n"
     ]
    }
   ],
   "source": [
    "print(*get_sentence_structure('dog\\'s food is good'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = 'Along with designing the non-academic calendar of the institute in consultation with the Dean of Student Affairs, the Student Council manages existing clubs through budgets and annual reports'\n",
    "extractions = extract(paragraph)\n",
    "write_json({paragraph: extractions}, '../data/demo/output.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNVVANNNCANNNNANNNNVVVANNANNNCNANAN ['Courier', 'boys', 'will', 'enter', 'through', 'gate', 'no', '1', 'after', 'parking', 'courier', 'boys', 'vehicle', 'in', 'main', 'parking', 'courier', 'boys', 'shall', 'be', 'directed', 'to', 'security', 'guard', 'at', 'gf', 'old', 'building', 'reception', 'for', 'delivery', 'of', 'courier']\n",
      "\n",
      "{'sentence': 'NNNVVVNAN', 'modifiers0': [], 'subject': ['No courier boy'], 'modifiers1': [], 'relation': ['will be allowed'], 'object': ['access'], 'modifiers2': [{'m_rel': ['inside'], 'm_obj': ['building']}]}\n",
      "{'sentence': 'AAN,NVN,NCN', 'modifiers0': [{'m_rel': ['because of'], 'm_obj': ['this']}], 'subject': ['I'], 'modifiers1': [], 'relation': ['eat'], 'object': ['icecream', 'milkshake', 'apple'], 'modifiers2': []}\n",
      "{'sentence': 'NVN', 'modifiers0': [], 'subject': ['I'], 'modifiers1': [], 'relation': ['did'], 'object': ['this'], 'modifiers2': []} {'sentence': 'NVN', 'modifiers0': [], 'subject': ['I'], 'modifiers1': [], 'relation': ['did'], 'object': ['that'], 'modifiers2': []}\n",
      "{'sentence': 'NVNAAN', 'modifiers0': [], 'subject': ['I'], 'modifiers1': [], 'relation': ['did'], 'object': ['this'], 'modifiers2': [{'m_rel': ['because of'], 'm_obj': ['that']}]}\n",
      "{'sentence': 'NNNNNVNNANANAN', 'modifiers0': [], 'subject': ['The U.S. president Barack Obama'], 'modifiers1': [], 'relation': ['gave'], 'object': ['his speech'], 'modifiers2': [{'m_rel': ['on'], 'm_obj': ['Tuesday']}, {'m_rel': ['to'], 'm_obj': ['thousands']}, {'m_rel': ['of'], 'm_obj': ['people']}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*get_sentence_structure('Courier boys will enter through gate no 1 and after parking courier boys vehicle in main parking courier boys shall be directed to security guard at gf old building or reception for delivery of courier.'))\n",
    "print(*extract('Courier boys will enter through gate no 1 and after parking courier boys vehicle in main parking courier boys shall be directed to security guard at gf old building or reception for delivery of courier.'))\n",
    "print(*extract(' No courier boy will be allowed access inside building'))\n",
    "print(*extract('because of this, I eat icecream, milkshake, and apple.'))\n",
    "print(*extract('I did this because I did that'))\n",
    "print(*extract('I did this because of that'))\n",
    "print(*extract('The U.S. president Barack Obama gave his speech on Tuesday to thousands of people.'))\n",
    "print(*extract('After graduating, he became a civil rights attorney and an academic, teaching constitutional law at the University of Chicago Law School from 1992 to 2004'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 904\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "text = read_text('../data/handbook_preprocessed_text.txt')\n",
    "# text = read_text('../data/wiki_sentences.txt')\n",
    "\n",
    "\n",
    "sentences_ = text.split('\\n')[:-1]\n",
    "sentences = []\n",
    "for sentence in sentences_:\n",
    "    sentences += split_into_sentences(sentence)\n",
    "\n",
    "count = 0\n",
    "extractions = {}\n",
    "short_sentences = []\n",
    "for sentence in sentences:\n",
    "    if len(sentence.split()) <= 4:\n",
    "        short_sentences.append(sentence)\n",
    "#     print(sentence)\n",
    "    ext = extract(sentence)\n",
    "#     print(ext)\n",
    "#     print()\n",
    "    if ext:\n",
    "        extractions[sentence] = ext\n",
    "        count += 1\n",
    "print(count, len(sentences))\n",
    "print(len(short_sentences))\n",
    "write_json(extractions, '../data/my_handbook_extractions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STUDENT', 'HANDBOOK 2017', 'Foreword', '3', 'Index', '5', 'About IIITD', '7', 'Campus and Infrastructure', 'Some Key Features', 'Energy', 'Waste Water Recycling', 'Fire-Fighting Equipment', 'Rainwater and Landscape', '9', 'Internet', 'The Campus', ' The Campus', 'Library and Information Center', '10', 'Neighbourhood', '11', 'Life at IIITD', 'Clubs', ' Clubs', ' Clubs', 'Sports and Recreation', '13', 'Gym', 'Fests and Events', '14', 'Community Work', 'and Self Growth', 'Counselling', '15', 'Mr. Khushpinder P', ' Sharma', '+91-9815181252 khushpinder@iiitd.ac.in', 'Dr. Amita Puri', '+91-7838732232 amitapuri@iiitd.ac.in', 'Dr. Akshay Kumar', '+91-9999801130 akshay@iiitd.ac.in', 'Attend orientations', 'Yes its important', 'Be money Wise', '16', 'Get Organized', 'Go to class', 'Priortising tasks', ' Learn to honor deadlines.', 'Handling homesickness', 'One last word', '.', '17', '19', 'Hostel Allotment', \"Students' Guests\", '20', '21', 'Other Facilities', 'Medical Facilities', '23', 'Photocopying and Scanning Facilities', '24', 'ATM Banking Facility', '25', 'Academics', 'Attendance Policy', 'Academic Rules', 'Ordinances for B.Tech', ' Program', 'Regulations for B.Tech', ' Program', 'Operational Guidelines for B.Tech', ' Program', '(CSE and ECE) Program', '27', 'Academic Evaluation', 'Medical Absence', '1', '28', '2', '1', '2', '3', '4', '5', 'Duplicate ID', 'Fee Payment', 'Fee Waiver or Scholarship', '29', 'Fee Structure', 'Plagiarism', '30', 'Contact Points', 'For program: Program Coordinator', '31', 'Relevant Policies', 'Vehicle Policy', 'Parking Policy', 'Anti-Ragging Policy', 'Disciplinary Action', '33', 'Honor Code', ' Honor Code', '34', 'IT Policy', '35', 'Student Governance and Employment', 'Student Council', 'Objectives of Student Council:', '37', 'Student Senate', 'Objectives of Student Senate:', '38', 'Student Employment', '39', 'Anit-Sexual Harassment Committee', ' Anit-Sexual Harassment Committee', '41', 'Grievance Redressal', 'Grievance', 'Course Related Academics Related', 'Hostels or Facilities related', 'Sexual Harassment', 'First Level', 'Instructor', 'AM or DM Academics', 'Second Level Third Level', 'Manager DoAA (Academics)', 'Anti-sexual harassment committee', 'GM(FMS) DOSA DOSA DOSA', 'Registrar', '43', 'Do’s and Don’ts', \"Do's\", 'Meet new people', 'Get involved', 'Attend classes regularly', 'Go to sporting event', 'Stay healthy', 'Don’ts', 'work done', 'Damaging institute’s property', 'Damaging institute’s property', '45', 'Useful Information', 'Sr', 'Contact Academic Section.', '47', 'Advice from Seniors', 'Planning Your Courses', 'Engineering Career', '49', 'Research Career', 'Entrepreneurship Career', 'In Research Career', '50', 'Do internship in startup', 'Management Career', 'Get Into Management', 'Do MBA After BTech', '51', 'Effective Study Habits', 'Lectures', '52', '(i) attend lectures and', 'Assignments', 'Weekly Revision or Sync-Up', '53', 'Prioritising Work', 'Group Study', 'Many prefer individual study', 'Group and Individual Projects', 'Help other students', '54', 'Academics gets first priority', '55', 'Time Management', 'Prioritizing', ' Prioritizing is very important', 'Plan', '56', 'Self Belief', ' No distractions at all', '57', ' That’s beauty here.', ' It depends on you', ' Study effectively in end.', '58', 'Advice for difficult core-courses', 'Attend classes', '59', ' Self study is must', '60', 'All best', '61', 'Important Phone Numbers', 'Dean (Academic)', 'Samaresh Chatterji (487)', 'Chairman and PGC', 'Rajiv Raman (573)', 'Chairperson and UGC', 'Anubha Gupta (428)', 'Registrar', 'B', ' Chandrasekar (419)', 'Vikram Goyal (474)', 'Student Affairs', 'Academic Section', 'Accounts Section', 'Amit Shankdhar (429)', 'Central Library', 'Rajendra Singh (510)', 'Facilities Management and Warden-IN-Charge', 'Arun Verma (562)', 'IT Help Desk', '(576)', 'Security', '9868244868 (592)', '63', 'Appendices', 'I - Parking Policy', 'II - Honor Code', 'student in IIIT Delhi:', '65', 'III - IT Policy', 'abide by following rules:', '1', '2', '3', '4', '5', '6', '7', 'Date: ___________________ SIgnature: ___________________', '66', 'Respect fellow being’s privacy.', '67', '68', 'DISCLAIMER', '69']\n"
     ]
    }
   ],
   "source": [
    "print(short_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AANVN,NNNVNNCNNVVANNANANNCN',\n",
       " ['Based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'specified',\n",
       "  'criteria',\n",
       "  'the',\n",
       "  'allotment',\n",
       "  'committee',\n",
       "  'recommends',\n",
       "  'the',\n",
       "  'allotment',\n",
       "  'the',\n",
       "  'list',\n",
       "  'is',\n",
       "  'published',\n",
       "  'on',\n",
       "  'the',\n",
       "  'website',\n",
       "  'with',\n",
       "  'instructions',\n",
       "  'for',\n",
       "  'necessary',\n",
       "  'payments',\n",
       "  'possession'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_structure( 'Based on the specified criteria, the allotment committee recommends the allotment and the list is published on the website with instructions for necessary payments & possession.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'NNVNNCNNAN',\n",
       "  'modifiers0': [],\n",
       "  'subject': ['Autonomous cars'],\n",
       "  'modifiers1': [],\n",
       "  'relation': ['shift'],\n",
       "  'object': ['insurance liability', 'moral responsibility'],\n",
       "  'modifiers2': [{'m_rel': ['toward'], 'm_obj': ['manufacturers']}]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('Autonomous cars shift insurance liability and moral responsibility toward manufacturers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NCNVCVNCNCNVV',\n",
       " ['Rohit',\n",
       "  'Rahul',\n",
       "  'eat',\n",
       "  'drink',\n",
       "  'snacks',\n",
       "  'drinks',\n",
       "  'they',\n",
       "  'study',\n",
       "  'together'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_structure('Rohit and Rahul eat and drink snacks and drinks and they study together.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('NNANNVVANVANNANNN',\n",
       " ['Visitor',\n",
       "  'entry',\n",
       "  'to',\n",
       "  'the',\n",
       "  'campus',\n",
       "  'is',\n",
       "  'allowed',\n",
       "  'from',\n",
       "  '8',\n",
       "  'am',\n",
       "  'to',\n",
       "  '10',\n",
       "  'pm',\n",
       "  'through',\n",
       "  'Gate',\n",
       "  'No',\n",
       "  '1'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(extract('Visitor entry to the campus is allowed from 8 am to 10 pm through Gate No 1.'))\n",
    "get_sentence_structure('Visitor entry to the campus is allowed from 8 am to 10 pm through Gate No 1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'NNANVANN',\n",
       "  'modifiers0': [],\n",
       "  'subject': ['All visitors'],\n",
       "  'modifiers1': [{'m_rel': ['entering'], 'm_obj': ['campus']}],\n",
       "  'relation': ['are under'],\n",
       "  'object': ['CCTV surveillance'],\n",
       "  'modifiers2': []},\n",
       " {'sentence': 'NNNVVANN',\n",
       "  'modifiers0': [],\n",
       "  'subject': ['the number plate'],\n",
       "  'modifiers1': [],\n",
       "  'relation': ['is recorded by'],\n",
       "  'object': ['the camera'],\n",
       "  'modifiers2': []}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('All visitors entering campus are under CCTV surveillance and the number plate is recorded by the camera.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('Any visitor coming to the building complex can gain entry through Gate No 1 only after confirmation from the staff members whom the visitor intends to meet or in the case of non-availability of the member, a confirmation has to be obtained from GM(Ops).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('After obtaining due clearance for the access, as mentioned above, the visitors coming in self-driven cars will be requested to park their car in the Parking Area near Academic Block.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'NNVNCNNANANN',\n",
       "  'modifiers0': [],\n",
       "  'subject': ['The Institute'],\n",
       "  'modifiers1': [],\n",
       "  'relation': ['collects'],\n",
       "  'object': ['tuition', 'hostels fee'],\n",
       "  'modifiers2': [{'m_rel': ['from'], 'm_obj': ['students']},\n",
       "   {'m_rel': ['on'], 'm_obj': ['semester basis']}]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('The Institute collects tuition and hostels fee from students on semester basis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'NAANVVVANN',\n",
       "  'modifiers0': [],\n",
       "  'subject': ['Purchase'],\n",
       "  'modifiers1': [{'m_rel': ['followed by'], 'm_obj': ['billing']}],\n",
       "  'relation': ['will be done at'],\n",
       "  'object': ['the counter'],\n",
       "  'modifiers2': []}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('Purchase followed by billing will be done at the counter.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonicalise extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723\n",
      "608\n",
      "591\n"
     ]
    }
   ],
   "source": [
    "extractions = read_json('../data/my_handbook_extractions.json')\n",
    "\n",
    "words = []\n",
    "relations = []\n",
    "for sentence in extractions:\n",
    "    for extraction in extractions[sentence]:\n",
    "        for sub in extraction['subject']:\n",
    "            words.append(sub)\n",
    "        for obj in extraction['object']:\n",
    "            words.append(obj)\n",
    "        for rel in extraction['relation']:\n",
    "            relations.append(rel)\n",
    "        for m in extraction['modifiers0']:\n",
    "            for obj in m['m_obj']:\n",
    "                words.append(obj)\n",
    "            for rel in m['m_rel']:\n",
    "                relations.append(rel)\n",
    "        for m in extraction['modifiers1']:\n",
    "            for obj in m['m_obj']:\n",
    "                words.append(obj)\n",
    "            for rel in m['m_rel']:\n",
    "                relations.append(rel)\n",
    "        for m in extraction['modifiers2']:\n",
    "            for obj in m['m_obj']:\n",
    "                words.append(obj)\n",
    "            for rel in m['m_rel']:\n",
    "                relations.append(rel)\n",
    "\n",
    "\n",
    "print(len(words))\n",
    "words = set(words)\n",
    "print(len(words))\n",
    "\n",
    "words = set(word.lower() for word in words)\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following entities need to be detected:\n",
    "* Locations: `gate`, `hostel` etc\n",
    "* Links: `https://`, emails\n",
    "* Numbers:\n",
    "    * Time: `hrs`, `date`, `am`, `pm`, etc\n",
    "    * Money `rs`, `rs.`, etc\n",
    "* Person:\n",
    "    * student: btech, mtech, phd, hosteller, day-scholar\n",
    "    * faculty: \n",
    "    * staff\n",
    "    * visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(entity):\n",
    "    if '\\'s' in entity:\n",
    "        entity = entity[entity.find('\\'s'):]\n",
    "    if '’s' in entity:\n",
    "        entity = entity[entity.find('’s'):]\n",
    "\n",
    "\n",
    "    # links\n",
    "    if 'http' in entity:\n",
    "        return 'ent:link:web'\n",
    "    if '@' in entity and ('.com' in entity or '.in'):\n",
    "        return 'ent:link:mail'\n",
    "    \n",
    "    # committee check\n",
    "    if 'committee' in entity or 'council' in entity or 'senate' in entity:\n",
    "        return 'ent:committee'\n",
    "\n",
    "    # location check\n",
    "    if 'gate' in entity:\n",
    "        if '1' in entity:\n",
    "            return 'ent:location:gate:1'\n",
    "        if '2' in entity:\n",
    "            return 'ent:location:gate:2'\n",
    "        if '3' in entity:\n",
    "            return 'ent:location:gate:3'\n",
    "        return 'ent:location:gate'\n",
    "    if 'hostel' in entity:\n",
    "        return 'ent:location:building:hostel'\n",
    "    if 'library' in entity:\n",
    "        return 'ent:location:building:library'\n",
    "    if 'sport' in entity and 'complex' in entity:\n",
    "        return 'ent:location:building:sports_block'\n",
    "    if 'canteen' in entity or 'mess' in entity or 'dining' in entity:\n",
    "        return 'entity:location:building:canteen'\n",
    "    if 'block' in entity:\n",
    "        if 'sem' in entity:\n",
    "            return 'ent:location:building:seminar_block'\n",
    "        if 'new' in entity and 'acad' in entity or 'r&d' in entity or 'research' in entity:\n",
    "            return 'ent:location:building:new_academic_block'\n",
    "        if 'acad' in entity:\n",
    "            return 'ent:location:building:acad_block'\n",
    "        if 'sport' in entity:\n",
    "            return 'ent:location:building:sports_block'\n",
    "        return 'ent:location:building'\n",
    "    if 'building' in entity or 'room' in entity or 'floor' in entity:\n",
    "        return 'ent:location'\n",
    "    \n",
    "    # concept check\n",
    "    if 'admission' in entity or 'admit' in entity:\n",
    "        return 'ent:topic:admission'\n",
    "    if 'park' in entity or 'vehicle' in entity:\n",
    "        return 'ent:topic:parking'\n",
    "    if 'course' in entity or 'academic' in entity or 'lectur' in entity:\n",
    "        return 'ent:topic:academic'\n",
    "    if 'fee' in entity or 'pay' in entity or 'charge' in entity:\n",
    "        return 'ent:topic:fee'\n",
    "    if 'concern' in entity or 'grievance' in entity or 'problem' in entity or 'issue' in entity:\n",
    "        return 'ent:topic:concerns'\n",
    "    \n",
    "    # person checks\n",
    "    if 'prof' in entity or 'faculty' in entity:\n",
    "        return 'ent:person:faculty'\n",
    "\n",
    "    if 'staff' in entity:\n",
    "        return 'ent:person:staff'\n",
    "\n",
    "    if 'student' in entity:\n",
    "        if 'btech' in entity or 'b.tech' in entity:\n",
    "            return 'ent:person:student:btech'\n",
    "        if 'mtech' in entity or 'm.tech' in entity:\n",
    "            return 'ent:person:student:mtech'\n",
    "        if 'phd' in entity:\n",
    "            return 'ent:person:student:phd'\n",
    "        if 'hostel' in entity:\n",
    "            return 'ent:person:student:hosteller'\n",
    "        return 'ent:person:student'\n",
    "    if 'hosteller' in entity:\n",
    "        return 'ent:person:hosteller'\n",
    "    if 'visitor' in entity:\n",
    "        return 'ent:person:visiter'\n",
    "\n",
    "\n",
    "    # check if it contains a number\n",
    "    isNumber = False\n",
    "    for char in entity:\n",
    "        if char in '1234567890':\n",
    "            isNumber = True\n",
    "    if isNumber:\n",
    "        # date\n",
    "        months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "        for month in months:\n",
    "            if month in entity:\n",
    "                return 'ent:number:date'\n",
    "        if re.match(entity, '*20..-*') or re.match(entity, '*19..-*') or re.match(entity, '*-20..*') or re.match(entity, '*/20..*'):\n",
    "            return 'ent:number:date'\n",
    "        # time\n",
    "        if 'day' in entity or 'hr' in entity or 'mins' in entity or 'minute' in entity or 'sec' in entity or 'am' in entity or 'pm' in entity:\n",
    "            return 'ent:number:time'\n",
    "        if 'rs' in entity:\n",
    "            return 'ent:number:money'\n",
    "        return 'ent:number'\n",
    "\n",
    "    # program check\n",
    "    if 'b.tech' in entity or 'btech' in entity or 'bachelor' in entity:\n",
    "        return 'ent:program:btech'\n",
    "    if 'm.tech' in entity or 'mtech' in entity or 'master' in entity:\n",
    "        return 'ent:program:mtech'\n",
    "    if 'phd' in entity:\n",
    "        return 'ent:program:phd'\n",
    "    if 'program' in entity or 'department' in entity:\n",
    "        return 'ent:program'\n",
    "\n",
    "   # org check\n",
    "    if 'iiit' in entity or 'campus' in entity or 'institute' in entity or 'college' in entity:\n",
    "        return 'ent:iiitd'\n",
    "    \n",
    "    return 'ent:other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "668 484\n",
      "ent:program:mtech\n",
      "['m.tech cb program', 'm.tech ece program', 'pg m.tech', 'm.tech labs', 'm.tech cse program']\n",
      "\n",
      "ent:committee\n",
      "['disciplinary committee', 'employment 36 anti sexual harrassment committee 40 grievance redressal', 'student senate', 'the student senate coordinator', 'student council', 'mess committee mess committee', 'institute ’s senate']\n",
      "\n",
      "ent:program:btech\n",
      "['b.tech ece program', 'b.tech', 'b.tech cse program', 'b.tech csd program', 'b.tech labs', 'btech scholarship', 'b.tech csam program', 'b.tech itss program']\n",
      "\n",
      "ent:topic:fee\n",
      "['the subsidized charges', 'one time payment which', 'payment basis', 'caution fees rs . 10', 'tuition fees rs . 2', 'charge']\n",
      "\n",
      "entity:location:building:canteen\n",
      "['dining block', 'mess charges', 'common mess', 'dining block houses gymnasium', 'mess']\n",
      "\n",
      "ent:person:student\n",
      "['under- graduate students', 'student leaves institute', 'students', 'students area', 'student life', 'new students', 'fresh students', 'iiit delhi student', 'delhi students whose jee rank', 'student', 'the students', 'student bed', 'v student charter model code', 'students affairs', 'other students', 'fresh students bank accounts', 'any student', 'top students', 'the student charter']\n",
      "\n",
      "ent:location\n",
      "['each room', 'buildings', 'academic building', 'server room', 'her room', 'room rent', 'the top floor', 'separate building', 'classrooms', 'common room', 'second floor', 'ground floor', 'first floor', 'the rooms']\n",
      "\n",
      "ent:iiitd\n",
      "['indraprastha institute', 'iiit delhi', 'campus life', 'delhi government the iiit delhi act', 'iiit delhi delhi computing', 'institute', 'banarsidas chandiwala institute', 'campus grounds', 'iiit delhi campus', 'the campus counselors', 'iiit- delhi iiit delhi', 'the institute', 'tedxiiitd event', 'the overall institute directory', 'campus', 'iiitd', 'delhi iiit delhi']\n",
      "\n",
      "ent:number\n",
      "['dd-23', '129 access points', '2007 to', '8', '000', 'infrastructure 8 life', '2017', '3 switches to', 'security ’s extension number 592', '45 50 min', 'don’ts 44 useful information 46 advice', '25 acres', '40 45 min', '2008', '49922222', '2000', '65 kl', 'layer 2', '10 % discount', '20 km', '500', '5 % discount', '2007', '50', '2 sewage treatment plants', '1 gbit', 'phase-3', '40-bed hospital']\n",
      "\n",
      "ent:number:money\n",
      "['rs 150', 'seniors 48 important phone numbers 50 appendices 64', 'rs 9', '000 rs 11', 'rs 200']\n",
      "\n",
      "ent:person:faculty\n",
      "['bug professors', 'faculty residences', 'faculty']\n",
      "\n",
      "ent:topic:parking\n",
      "['some parking', 'any vehicle', 'all vehicles', 'the vehicles', 'parking policy', 'the complete vehicle']\n",
      "\n",
      "ent:location:building:hostel\n",
      "['refundable hostel fees rs 64', 'hostel fees', 'hostel common rooms', 'hostel blocks', 'hostels', 'iiit delhi 12 hostel', 'hostel related communications', 'hostel']\n",
      "\n",
      "ent:topic:admission\n",
      "['admission', 'admissions', 'btech admission']\n",
      "\n",
      "ent:topic:academic\n",
      "['cafeteria 18 other facilities 22 academics 26 relevant policies 32 student governance', '3 zones academic', 'schedule 6th course 10 hrs', 'course related academics', 'academic interests', 'academics', 'we non academic interest', 'transcripts academic section', 'academic misconduct', 'lectures', 'other academic issues course registration', 'courses', 'core courses', 'difficult core courses', '6th course', 'other courses', 'academic']\n",
      "\n",
      "ent:topic:concerns\n",
      "['problem', 'grievances', 'target problems', 'concerned doctor', 'unnecessary health issues', 'concerns', 'issue']\n",
      "\n",
      "ent:person:student:btech\n",
      "['60 b.tech students', 'b.tech cse students']\n",
      "\n",
      "ent:program:phd\n",
      "['phd program']\n",
      "\n",
      "ent:location:building:sports_block\n",
      "['the new sports block']\n",
      "\n",
      "ent:location:building:library\n",
      "['library building', 'library', 'the library']\n",
      "\n",
      "ent:program\n",
      "['relevant departments', 'programming', 'departmental store', 'it department']\n",
      "\n",
      "ent:number:date\n",
      "['8th september', '10th june']\n",
      "\n",
      "ent:location:building\n",
      "['all blocks', 'faculty block', 'service block']\n",
      "\n",
      "ent:link:web\n",
      "['http://www.iiitd.ac.in/education/ resources', 'website https://www.iiitd ac.in', 'https://www iiitd.ac.in', 'https://iiitd.ac.in/academics/courses']\n",
      "\n",
      "ent:location:gate:1\n",
      "['gate no 1']\n",
      "\n",
      "ent:person:visiter\n",
      "['any other visitor']\n",
      "\n",
      "ent:number:time\n",
      "['8 pm', '15:00 16:00 hrs', 'free 24 hr ambulance services', '24 hrs icu']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_type = {}\n",
    "for word in words:\n",
    "    if get_type(word) != 'ent:other':\n",
    "        entity_type[word] = get_type(word)\n",
    "#     else:\n",
    "#         print(word)\n",
    "print()\n",
    "# for entity in entity_type:\n",
    "#     print(entity, ':', entity_type[entity])\n",
    "\n",
    "print(len(words), len(words) - len(entity_type))\n",
    "\n",
    "groups = {}\n",
    "for entity in entity_type:\n",
    "    if entity_type[entity] not in groups:\n",
    "        groups[entity_type[entity]] = []\n",
    "    groups[entity_type[entity]].append(entity)\n",
    "reduction = 0\n",
    "for group in groups:\n",
    "    reduction += (len(groups[group]) - 1)\n",
    "\n",
    "for group in groups:\n",
    "    print(group)\n",
    "    print(groups[group])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453\n",
      "204\n",
      "{'Help', 'for', 'has', 'are based on', 'inside', 'are connected through', 'can get', 'is approved by', 'are there for', 'are strictly prohibited', 'by', 'may be between', 'to', 'containing', 'is as', 'may go', 'functions during', 'may be contacted in', 'is very', 'are elected', 'by dialling', 'was hugely', 'is provided in', 'IN', 'has been contracted for providing', 'is about trying', 'is recycled using', 'will be deactivated from', 'safeguard', 'will be sent to', 'may hire', 'gets', 'was officially established on', 'as much', 'currently has', 'about putting in', 'also form', 'is always', 'done', 'can', 'know', 'are planned together by', 'are given in', 'are monitored by', 'will help ensure', 'during', 'improve', 'shall do so from', 'jointly held by', 'are organizing', 'are provided', 'allow', 'has been opened on', 'was created', 'will be referred to', 'shall be done via', 'began with', 'is', 'taking', 'is equipped with', 'may also visit', 'contact for', 'constitute', 'of using', 'should follow', 'are under', 'is defined in', 'might feel', 'so generated is used for', 'of', 'avoid', 'is in', 'from', 'do', 'may be verified from', 'attend', 'OF', 'may visit', 'will still be highly valued', 'reported by', 'at', 'is spread over', 'provide for', 'will be treated', 'too', 'at all', 'promote', 'posted in', 'may feel too', 'was held on', 'is also enabled in', 'contact for lost', 'for existing', 'is provided with', 'in opening', 'with', 'monitors', 'needing', 'generated in', 'provide', 'has been worked out with', 'are invited during', 'extends', 'also offers photocopying', 'am', 'is taken in', 'formulated by', 'is divided into', 'being', 'maintain', 'as', 'is effectively', 'prefer', 'offers', 'best', 'is permitted in', 'governing', 'are strictly', 'within', 'empowering', 'between', 'take', 'are revised annually', 'using', 'regarding', 'including', 'requiring', 'may also get', 'offered is given below', 'can be applied in', 'will house', 'assist', 'emerged are', 'above', 'will be considered', 'Regarding', 'will result in', 'can also be arranged on', 'are expected to', 'served in', 'will send', 'related', 'can often trigger', 'solving', 'are', 'helps', 'is highly', 'is located on', 'may approach', 'is appended', 'also organize', 'will be charged from', 'related to', 'is approximately', 'will get', 'is housed in', 'is located in', 'up can really be very', 'Where', 'into', 'effectively', 'can only be met in', 'shall keep', 'is must', 'have also been provided', 'in', 'can be transferred to', 'will be allotted according to', 'represent', 'should make', 'depends on', 'will', 'is at', 'per', 'Fighting', 'is be', 'located at', 'on', 'scanning', 'is fully automated using', 'for purchasing', 'caused to', 'specified above', 'entering', 'regularly', 'will be fined', 'Related', 'will be', 'provides', 'is strictly prohibited on', 'learn', 'patients', 'facilitate', 'needed by', 'allowed without', 'also suffers leading to', 'found', 'are created for', 'on in', 'need', 'functions during working', 'also uphold', 'should consider', 'of leaving'}\n"
     ]
    }
   ],
   "source": [
    "extractions = read_json('../data/my_handbook_extractions.json')\n",
    "rels = []\n",
    "for sentence in extractions:\n",
    "    for extraction in extractions[sentence]:\n",
    "        for rel in extraction['relation']:\n",
    "            rels.append(rel)\n",
    "        for modifier in extraction['modifiers0'] + extraction['modifiers1'] + extraction['modifiers2']:\n",
    "            for rel in modifier['m_rel']:\n",
    "                rels.append(rel)\n",
    "print(len(rels))\n",
    "rels = set(rels)\n",
    "print(len(rels))\n",
    "print(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract('Chairman’s Merit Scholarship in BTech admission for top students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
